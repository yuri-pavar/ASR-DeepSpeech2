train:
  _target_: src.datasets.librispeech_kaggle.LibrispeechDatasetKaggle
  part: "dev-clean"
  # max_audio_length: 20.0
  # max_text_length: 200
  limit: 64 # if not None, limit the total number of elements in the dataset to 'limit' elements.
  max_audio_length: null
  max_text_length: null
  # limit: null
  instance_transforms: ${transforms.instance_transforms.train}
# we filter partitions in one batch test to check the pipeline
# do not filter test dataset, you want to evaluate on the whole dataset 
val:
  _target_: src.datasets.librispeech_kaggle.LibrispeechDatasetKaggle
  part: "dev-clean"
  # max_audio_length: 20.0
  # max_text_length: 200
  limit: 64
  max_audio_length: null
  max_text_length: null
  # limit: null
  instance_transforms: ${transforms.instance_transforms.inference}
